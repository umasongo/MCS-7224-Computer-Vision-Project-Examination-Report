{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1256b8",
   "metadata": {},
   "source": [
    "# MASONGO UMAR\n",
    "1800738510         2018/HD05/1967U\n",
    "## MASTER OF SCIENCE IN COMPUTER SCIENCE\n",
    "COMPUTER VISION PROJECT EXAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e7fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building file list...\n",
      "160 positive files and 54 negative files found.\n",
      "\n",
      "Converting images to BGR color space and extracting HOG, color histogram, spatial features from channel(s) 0, 1, 2.\n",
      "\n",
      "Features extracted from 214 files in 53.1 seconds\n",
      "\n",
      "Scaling features.\n",
      "\n",
      "Shuffling samples into training, cross-validation, and test sets.\n",
      "\n",
      "120 samples in positive training set.\n",
      "32 samples in positive cross-validation set.\n",
      "8 samples in positive test set.\n",
      "160 total positive samples.\n",
      "\n",
      "40 samples in negative training set.\n",
      "11 samples in negative cross-validation set.\n",
      "3 samples in negative test set.\n",
      "54 total negative samples.\n",
      "\n",
      "Loading sample data.\n",
      "Training classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umar/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 2.3 s.\n",
      "\n",
      "Val set false negatives: 1 / 32 (96.9% accuracy)\n",
      "Val set false positives: 0 / 11 (100.000% accuracy)\n",
      "Val set total misclassifications: 1 / 43 (97.674% accuracy)\n",
      "\n",
      "Augmenting training set with misclassified validation samples and retraining classifier.\n",
      "\n",
      "Test set false negatives: 0 / 8 (1e+02% accuracy)\n",
      "Test set false positives: 0 / 3 (100.000% accuracy)\n",
      "Test set total misclassifications: 0 / 11 (100.000% accuracy)\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage.measurements import label\n",
    "%run hogDescriptor.ipynb\n",
    "%run slideWindow.ipynb\n",
    "%run processTrain.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c925bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "\n",
    "    # This class is used to detect objects(Cassava) in a video stream\n",
    "    # A pretrained SVM is loaded from trainSVM file and used\n",
    "    \n",
    "    descriptor = Descriptor()\n",
    "     \n",
    "    def __init__(self, init_size=(64,64), x_overlap=0.0463, y_step=0.0261,\n",
    "            x_range=(0, 1.0), y_range=(0, 1.0), scale=1.0):\n",
    "        \n",
    "        # Input arguments that set the sliding window parameters as defined in the slidingWindow file\n",
    "\n",
    "        self.init_size = init_size\n",
    "        self.x_overlap = x_overlap\n",
    "        self.y_step = y_step\n",
    "        self.x_range = x_range\n",
    "        self.y_range = y_range\n",
    "        self.scale = scale\n",
    "        self.windows = None\n",
    "        \n",
    "    def loadClassifier(self, filepath=None, classifier_data=None):\n",
    "        \n",
    "        # Load a classifier trained by trainSVM function in processTrain.ipynb Either a dict\n",
    "        # (classifier_data) or pickled file (filepath) can be supplied.\n",
    "    \n",
    "        if filepath is not None:\n",
    "            filepath = os.path.abspath(filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                raise FileNotFoundError(\"File \" + filepath + \" does not exist.\")\n",
    "            classifier_data = pickle.load(open(filepath, \"rb\"))\n",
    "        else:\n",
    "            classifier_data = classifier_data\n",
    "\n",
    "        if classifier_data is None:\n",
    "            raise ValueError(\"Invalid classifier data supplied.\")\n",
    "\n",
    "        self.classifier = classifier_data[\"classifier\"]\n",
    "        self.scaler = classifier_data[\"scaler\"]\n",
    "        self.cv_color_const = classifier_data[\"cv_color_const\"]\n",
    "        self.channels = classifier_data[\"channels\"]\n",
    "        self.descriptor = Descriptor(\n",
    "                hog_features=classifier_data[\"hog_features\"],\n",
    "                hist_features=classifier_data[\"hist_features\"],\n",
    "                spatial_features=classifier_data[\"spatial_features\"],\n",
    "                hog_lib=classifier_data[\"hog_lib\"],\n",
    "                size=classifier_data[\"size\"],\n",
    "                hog_bins=classifier_data[\"hog_bins\"],\n",
    "                pix_per_cell=classifier_data[\"pix_per_cell\"],\n",
    "                cells_per_block=classifier_data[\"cells_per_block\"],\n",
    "                block_stride=classifier_data[\"block_stride\"],\n",
    "                block_norm=classifier_data[\"block_norm\"],\n",
    "                transform_sqrt=classifier_data[\"transform_sqrt\"],\n",
    "                signed_gradient=classifier_data[\"signed_gradient\"],\n",
    "                hist_bins=classifier_data[\"hist_bins\"],\n",
    "                spatial_size=classifier_data[\"spatial_size\"])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def classify(self, image):\n",
    "        \n",
    "        # Classify windows of an image as \"positive\" (Contains banana crop) or \"negative\" (contains other crops)\n",
    "        # Return a list of positively classified windows.\n",
    "        \n",
    "        if self.cv_color_const > -1:\n",
    "            image = cv2.cvtColor(image, self.cv_color_const)\n",
    "\n",
    "        if len(image.shape) > 2:\n",
    "            image = image[:, :, self.channels]\n",
    "        else:\n",
    "            image = image[:, :, np.newaxis]\n",
    "\n",
    "        #feature_vectors = [Descriptor.getFeatureVector(descriptor,\n",
    "                #image[y_upper:y_lower, x_upper:x_lower, :])\n",
    "            #for (x_upper, y_upper, x_lower, y_lower) in self.windows]\n",
    "        \n",
    "        feature_vectors = [descriptor.getFeatureVector(\n",
    "                image[y_upper:y_lower, x_upper:x_lower, :])\n",
    "            for (x_upper, y_upper, x_lower, y_lower) in self.windows]\n",
    "            \n",
    "        # feature_vectors = self.to_matrix(feature_vectors, 2)\n",
    "\n",
    "        # Scale feature vectors, predict, and return predictions\n",
    "        feature_vectors = self.scaler.transform(feature_vectors)\n",
    "        predictions = self.classifier.predict(feature_vectors)\n",
    "        \n",
    "        return [self.windows[ind] for ind in np.argwhere(predictions == 1)[:,0]]\n",
    "    \n",
    "    def crop_detection(self, video_capture=None, num_frames=9, threshold=120,\n",
    "            min_bbox=None, show_video=True, draw_heatmap=True,\n",
    "            draw_heatmap_size=0.2, write=False, write_fps=24):\n",
    "        \n",
    "        cap = video_capture\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error opening VideoCapture.\")\n",
    "        (grabbed, frame) = cap.read()\n",
    "        (h, w) = frame.shape[:2]\n",
    "\n",
    "        # Store coordinates of all windows to be checked at every frame.\n",
    "        self.windows = slidingWindow((w, h), init_size=self.init_size,\n",
    "                x_overlap=self.x_overlap, y_step=self.y_step,\n",
    "                x_range=self.x_range, y_range=self.y_range, scale=self.scale)\n",
    "\n",
    "        if min_bbox is None:\n",
    "            min_bbox = (int(0.02 * w), int(0.02 * h))\n",
    "\n",
    "        # Heatmap inset size.\n",
    "        inset_size = (int(draw_heatmap_size * w), int(draw_heatmap_size * h))\n",
    "\n",
    "        if write:\n",
    "            vidFilename = datetime.now().strftime(\"%Y%m%d%H%M\") + \".avi\"\n",
    "            fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "            writer = cv2.VideoWriter(vidFilename, fourcc, write_fps, (w, h))\n",
    "\n",
    "        # Compute the heatmap for each frame and store in current_heatmap.\n",
    "        # Store the last num_frames heatmaps in deque last_N_frames. At each\n",
    "        # frame, sum in the deque to compute summed_heatmap. After\n",
    "        # thresholding, label blobs in summed_heatmap with\n",
    "        # scipy.ndimage.measurements.label and store in heatmap_labels.\n",
    "        current_heatmap= np.zeros((frame.shape[:2]), dtype=int)\n",
    "        summed_heatmap = np.zeros_like(current_heatmap, dtype=int)\n",
    "        last_N_frames = deque(maxlen=num_frames)\n",
    "        heatmap_labels = np.zeros_like(current_heatmap, dtype=int)\n",
    "\n",
    "        # Weights for the frames in last_N_frames for producing summed_heatmap.\n",
    "        # Recent frames are weighted more heavily than older frames.\n",
    "        weights = np.linspace(1 / (num_frames + 1), 1, num_frames)\n",
    "        while True:\n",
    "            (grabbed, frame) = cap.read()\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            current_heatmap[:] = 0\n",
    "            summed_heatmap[:] = 0\n",
    "            for (x_upper, y_upper, x_lower, y_lower) in self.classify(frame):\n",
    "                current_heatmap[y_upper:y_lower, x_upper:x_lower] += 10\n",
    "\n",
    "            last_N_frames.append(current_heatmap)\n",
    "            for i, heatmap in enumerate(last_N_frames):\n",
    "                cv2.add(summed_heatmap, (weights[i] * heatmap).astype(np.uint8),\n",
    "                    dst=summed_heatmap)\n",
    "\n",
    "            # Apply blur and/or dilate to the heatmap.\n",
    "            #cv2.GaussianBlur(summed_heatmap, (5,5), 0, dst=summed_heatmap)\n",
    "            cv2.dilate(summed_heatmap, np.ones((7,7), dtype=np.uint8),\n",
    "                dst=summed_heatmap)\n",
    "\n",
    "            if draw_heatmap:\n",
    "                inset = cv2.resize(summed_heatmap, inset_size,\n",
    "                    interpolation=cv2.INTER_AREA)\n",
    "                inset = cv2.cvtColor(inset, cv2.COLOR_GRAY2BGR)\n",
    "                frame[:inset_size[1], :inset_size[0], :] = inset\n",
    "\n",
    "            # Ignore heatmap pixels below threshold.\n",
    "            summed_heatmap[summed_heatmap <= threshold] = 0\n",
    "\n",
    "            # Label remaining blobs with scipy.ndimage.measurements.label.\n",
    "            num_objects = label(summed_heatmap, output=heatmap_labels)\n",
    "\n",
    "            # Determine the largest bounding box around each object.\n",
    "            for obj in range(1, num_objects + 1):\n",
    "                (Y_coords, X_coords) = np.nonzero(heatmap_labels == obj)\n",
    "                x_upper, y_upper = min(X_coords), min(Y_coords)\n",
    "                x_lower, y_lower = max(X_coords), max(Y_coords)\n",
    "\n",
    "                # Only draw box if object is larger than min bbox size.\n",
    "                if (x_lower - x_upper > min_bbox[0]\n",
    "                        and y_lower - y_upper > min_bbox[1]):\n",
    "                    cv2.rectangle(frame, (x_upper, y_upper), (x_lower, y_lower),\n",
    "                        (0, 255, 0), 6)\n",
    "\n",
    "            if write:\n",
    "                writer.write(frame)\n",
    "\n",
    "            if show_video:\n",
    "                cv2.imshow(\"Detection\", frame)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if write:\n",
    "            writer.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96c34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the banana detector\n",
    "banana_detector = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f8e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set desired sliding window parameters\n",
    "banana_detector = Detector(init_size=(64, 64), x_overlap=0.0463, y_step=0.0261, x_range=(0, 1.0), y_range=(0, 1.0), scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f5f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Detector at 0x7fe205931d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load classifier from dict\n",
    "banana_detector.loadClassifier(filepath=None, classifier_data=classifier_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b521a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the detector on a video by creating an OpenCV VideoCapture object and\n",
    "# supplying it to Detector.detectVideo()\n",
    "\n",
    "cap = cv2.VideoCapture(\"./hog_image/Garden_Video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175a4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
